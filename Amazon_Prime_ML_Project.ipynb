{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    -CineScore AI: Intelligent IMDb Rating Predictor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "### **📌 Project Summary: IMDb Score Prediction & Movie Analysis**  \n",
        "\n",
        "#### **🔹 Objective**  \n",
        "The project focuses on **predicting IMDb scores** for movies and TV shows using **machine learning models**. The dataset includes **movie metadata, genres, ratings, and popularity metrics**, which are analyzed and preprocessed to build a predictive model.  \n",
        "\n",
        "---\n",
        "\n",
        "#### **🔹 Data Preprocessing & Feature Engineering**  \n",
        "✔ **Handling Missing Values:** Imputed missing numerical values with **mean** and categorical values with **\"Unknown\"**.  \n",
        "✔ **Outlier Treatment:** Used the **IQR method** to remove extreme values.  \n",
        "✔ **Categorical Encoding:** Converted **genres, type, and age certification** into numerical values using **Label Encoding**.  \n",
        "✔ **Text Preprocessing:** Applied **TF-IDF vectorization** on descriptions and performed **dimensionality reduction (Truncated SVD)** to reduce feature complexity.  \n",
        "✔ **Feature Selection:** Used **Variance Threshold, Random Forest Importance, and SelectKBest (ANOVA F-test)** to select the most relevant features.  \n",
        "✔ **Scaling & Transformation:** Applied **Standard Scaling and Power Transformation** to normalize numerical features.  \n",
        "\n",
        "---\n",
        "\n",
        "#### **🔹 Data Splitting & Handling Imbalance**  \n",
        "✔ **Train-Test Split (80-20 Ratio):** Ensured a balanced training and evaluation process.  \n",
        "✔ **Checked for Class Imbalance:** Identified imbalance in **IMDb score categories (high vs. low-rated movies)**.  \n",
        "✔ **Used SMOTE (If Needed):** Oversampled the minority class to prevent model bias.  \n",
        "\n",
        "---\n",
        "\n",
        "#### **🔹 Model Training & Evaluation**  \n",
        "✔ **Trained Gradient Boosting Regressor:** A powerful ensemble learning model for predicting IMDb scores.  \n",
        "✔ **Handled NaN values in Features:** Used **SimpleImputer (Mean Strategy)** before training.  \n",
        "✔ **Evaluated Model Performance:** Measured using:  \n",
        "   - **Mean Squared Error (MSE)** → Measures overall prediction error.  \n",
        "   - **Mean Absolute Error (MAE)** → Shows average prediction error.  \n",
        "   - **R-squared Score (R²)** → Evaluates how well the model explains variance in IMDb scores.  \n",
        "\n",
        "---\n",
        "\n",
        "#### **🔹 Key Insights & Conclusion**  \n",
        "📌 **Movie genres and popularity significantly impact IMDb ratings.**  \n",
        "📌 **Textual features (e.g., movie descriptions) contribute heavily to score prediction.**  \n",
        "📌 **Feature selection & dimensionality reduction improved model performance.**  \n",
        "📌 **Handling missing values and scaling numerical features prevented skewed results.**  \n",
        "📌 **Gradient Boosting Regressor showed strong performance in predicting IMDb scores.**  \n",
        "\n",
        "---\n",
        "\n",
        "### **🚀 Final Outcome**  \n",
        "This project successfully built a **machine learning model** that predicts IMDb scores using **movie metadata, text features, and ratings**. The approach ensured **data quality, feature selection, and proper handling of imbalanced data** to achieve **accurate and reliable predictions**.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "Provide your GitHub Link here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "The entertainment industry produces a vast amount of content across various genres, formats, and platforms. However, understanding key trends in film and television production, the influence of cast and crew on a title’s success, and the factors that contribute to high ratings remains a challenge.\n",
        "\n",
        "This project aims to perform Exploratory Data Analysis (EDA) and Machine Learning(ML) on a merged dataset containing movie/show metadata and cast/crew details. The objective is to uncover insights related to:\n",
        "\n",
        "The most common and influential actors, directors, and other film industry roles. Patterns in movie/show genres, runtimes, and production trends over time. The relationship between various factors (such as genre, runtime, and cast) and performance metrics (IMDb and TMDb ratings). By analyzing these factors, this project will provide a data-driven understanding of the entertainment industry, helping stakeholders such as production companies, casting directors, and streaming services make informed decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgbUHAGgjLW"
      },
      "source": [
        "# **General Guidelines** : -  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      },
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "titles_df = pd.read_csv('/content/titles.csv')\n",
        "credits_df = pd.read_csv('/content/credits.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "titles_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "titles_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "titles_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "titles_df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values=titles_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values\n",
        "missing_df = pd.DataFrame(missing_values, columns=['Missing Values']).reset_index()\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(y='index', x='Missing Values', data=missing_df, palette='viridis')\n",
        "plt.xlabel(\"Number of Missing Values\")\n",
        "plt.ylabel(\"Columns\")\n",
        "plt.title(\"Missing Values Count per Column\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "The dataset consists of movie and TV show metadata (titles.csv) and cast/crew details (credits.csv), containing features like title, description, genres, release year, IMDb & TMDB scores, runtime, and roles of actors/directors. Missing values exist in key fields such as description, age certification, seasons, and IMDb/TMDB scores, requiring data cleaning. The dataset supports various ML applications, including movie recommendation systems (using text similarity), IMDb/TMDB score prediction (via regression), and actor-based recommendations. Data preprocessing, such as handling missing values and normalizing scores, is crucial for better model performance. So far, I have visualized missing values, built a TF-IDF-based recommendation system, and integrated the ML pipeline into your Jupyter Notebook for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "titles_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "titles_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "The **`titles.csv`** dataset contains metadata for movies and TV shows, including `id` (unique identifier), `title`, `type` (MOVIE/SHOW), `description`, `release_year`, `age_certification` (content rating), `runtime` (duration in minutes), `genres`, `production_countries`, `seasons` (for shows), and popularity metrics like `imdb_score`, `imdb_votes`, `tmdb_popularity`, and `tmdb_score`. The **`credits.csv`** dataset includes information about cast and crew, with columns like `person_id` (unique actor/crew ID), `id` (linking to titles.csv), `name` (actor/crew member), `character` (for actors), and `role` (`ACTOR`, `DIRECTOR`, etc.). These datasets support various ML tasks, such as recommendation systems, rating predictions, and cast-based analytics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable.\n",
        "unique_values = titles_df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJF3rekwFvQ"
      },
      "source": [
        "### Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "outputs": [],
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Ensure all descriptions are strings\n",
        "titles_df['description'] = titles_df['description'].astype(str)\n",
        "\n",
        "# Convert genres and production countries from string lists to actual lists\n",
        "titles_df['genres'] = titles_df['genres'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n",
        "titles_df['production_countries'] = titles_df['production_countries'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(titles_df['description'])\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a mapping of movie titles to indices\n",
        "indices = pd.Series(titles_df.index, index=titles_df['title']).drop_duplicates()\n",
        "\n",
        "def recommend_movies(title, num_recommendations=5):\n",
        "    if title not in indices:\n",
        "        return \"Title not found in dataset.\"\n",
        "\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:num_recommendations+1]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    return titles_df[['title', 'imdb_score']].iloc[movie_indices]\n",
        "\n",
        "# Example usage\n",
        "recommendations = recommend_movies(\"The General\", 5)\n",
        "print(recommendations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "I performed multiple data manipulations, including handling missing values by filling in empty descriptions with an empty string, replacing missing numerical fields (IMDb score, votes, TMDB popularity, and score) with their respective mean or median values, and converting `genres` and `production_countries` from string lists to actual lists. Duplicates were removed to ensure data consistency. To analyze data quality, I visualized missing values using a bar chart. For insights, I implemented a **TF-IDF vectorization** approach to convert movie descriptions into numerical vectors and computed **cosine similarity** to find similar movies. Finally, I developed a **recommendation function** that suggests movies based on textual similarity in descriptions. The approach effectively finds related movies, but incorporating additional features like genre and cast could further enhance the recommendation accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Missing Values Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(titles_df.isnull(), cmap=\"viridis\", cbar=False)\n",
        "plt.title(\"Missing Values Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "A heatmap effectively visualizes missing data patterns, helping identify columns with a high percentage of NaN values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "\n",
        "*  \"age_certification\" and \"seasons\" had the highest missing values.\n",
        "*  \"imdb_score\" and \"imdb_votes\" had some missing data, which needed imputation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "1.Handling missing values improves data quality, making models more accurate.\n",
        "2.Filling gaps in IMDb scores helps in better movie ranking and recommendations.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "If missing values are incorrectly imputed, it could lead to biased predictions and incorrect business decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Distribution of IMDb Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(titles_df['imdb_score'], bins=30, kde=True, color='blue')\n",
        "plt.xlabel(\"IMDb Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of IMDb Scores\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "A histogram with a KDE (Kernel Density Estimation) plot shows the spread and distribution of IMDb scores across the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "\n",
        "\n",
        "*  IMDb scores followed a normal distribution with most values between 5 and 8.\n",
        "* Very few movies had extremely low (≤3) or high (≥9) ratings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "1.Understanding IMDb score distribution helps in benchmarking new content performance.\n",
        "\n",
        "2.Helps production studios set expectations on audience reception.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "If a business focuses only on high-rated movies, it might ignore niche audiences who enjoy lower-rated but cult-favorite films."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "#### Count of Movies vs. Shows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='type', data=titles_df, palette='Set2')\n",
        "plt.xlabel(\"Content Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Count of Movies vs. Shows\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fge-S5ZAYoAp"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBItgRVYoAp"
      },
      "source": [
        "A scatter plot helps determine the relationship between IMDb scores and TMDB scores, two critical rating metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85gYPyotYoAp"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jstXR6OYoAp"
      },
      "source": [
        "1.A positive correlation was observed, meaning movies with higher IMDb scores also tend to have higher TMDB scores.\n",
        "\n",
        "2.Some outliers had high TMDB scores but low IMDb scores, indicating possible rating biases across platforms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoGjAbkUYoAp"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "Helps businesses identify anomalies in ratings across different platforms.\n",
        "\n",
        "Streaming platforms can adjust recommendations based on cross-platform trends.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "If businesses over-rely on one rating system, they may misjudge audience preferences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "#### Top 10 Most Common Genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "from collections import Counter\n",
        "\n",
        "genre_list = [genre for sublist in titles_df['genres'] for genre in sublist]\n",
        "genre_counts = Counter(genre_list).most_common(10)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=[x[1] for x in genre_counts], y=[x[0] for x in genre_counts], palette='magma')\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Genre\")\n",
        "plt.title(\"Top 10 Most Common Genres\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iky9q4vBYrdO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRCwT6DYrdO"
      },
      "source": [
        "A scatter plot helps analyze whether movies with more votes tend to have higher IMDb scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T5p64dYrdO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "Movies with fewer votes had highly fluctuating IMDb scores.\n",
        "\n",
        "High-rated movies (IMDb ≥ 8) generally had a large number of votes, indicating strong audience engagement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ehk30pYrdP"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "Helps platforms prioritize high-rated & high-engagement movies for better recommendations.\n",
        "\n",
        "Studios can invest in marketing to increase audience engagement.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "Low-vote movies with high quality might be overlooked, impacting niche genres and indie films.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "#### Movies Per Year Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "outputs": [],
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.histplot(titles_df['release_year'], bins=50, kde=True, color='green')\n",
        "plt.xlabel(\"Release Year\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Movies Per Year Distribution\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxuIMRPYuh3"
      },
      "source": [
        "A bar chart is effective in showing the most and least popular genres in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzvFGzlYuh3"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyqkiB8YYuh3"
      },
      "source": [
        "Drama, Comedy, and Action were the most common genres.\n",
        "Musicals and Documentaries were the least frequent categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpmQ266Yuh3"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "Helps streaming platforms optimize their content library by balancing popular and niche genres.\n",
        "\n",
        "Production houses can identify trends and invest in trending genres.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "Overproducing popular genres may saturate the market, leading to reduced audience interest.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### IMDb Score vs. TMDB Score Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(x=titles_df['imdb_score'], y=titles_df['tmdb_score'], alpha=0.6)\n",
        "plt.xlabel(\"IMDb Score\")\n",
        "plt.ylabel(\"TMDB Score\")\n",
        "plt.title(\"IMDb Score vs. TMDB Score Correlation\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFf2-_FphqN"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loh7H2nzphqN"
      },
      "source": [
        "A box plot effectively shows how IMDb scores vary by genre, including median ratings and outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouA3fa0phqN"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VECbqPI7phqN"
      },
      "source": [
        "Documentaries and Sci-Fi movies had higher median IMDb scores.\n",
        "\n",
        "Horror movies had a wider range of scores, indicating more variation in audience reception."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seke61FWphqN"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW4_bGpfphqN"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "Helps investors and studios identify which genres consistently get high ratings.\n",
        "\n",
        "Streaming platforms can curate high-quality content based on genre rating trends.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "Over-reliance on genre-based scores might discourage innovation in lower-rated genres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "#### IMDb Scores by Content Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x='type', y='imdb_score', data=titles_df, palette='coolwarm')\n",
        "plt.xlabel(\"Content Type\")\n",
        "plt.ylabel(\"IMDb Score\")\n",
        "plt.title(\"IMDb Scores by Content Type\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t27r6nlMphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv6ro40sphqO"
      },
      "source": [
        "A box plot helps compare IMDb scores across different production countries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2jJGEOYphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po6ZPi4hphqO"
      },
      "source": [
        "Movies from certain countries (e.g., UK, France, and South Korea) tend to have higher median scores.\n",
        "\n",
        "Wider variation in IMDb scores for Hollywood films, likely due to a large number of movies spanning all quality levels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0JNsNcRphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSq8iUTphqO"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "Helps businesses understand country-wise audience preferences.\n",
        "\n",
        "Streaming platforms can expand international content based on top-rated countries.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "Underestimating lower-rated country content may result in lost opportunities in emerging film industries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZR9WyysphqO"
      },
      "source": [
        "#### Distribution of Movie/Show Runtimes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(titles_df['runtime'], bins=30, kde=True, color='purple')\n",
        "plt.xlabel(\"Runtime (minutes)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Movie/Show Runtimes\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7wYXLtphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob8u6rCTphqO"
      },
      "source": [
        "A line chart shows how IMDb ratings have changed over the years."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZrbJ2SmphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZtgC_hjphqO"
      },
      "source": [
        "Older movies (pre-2000) had higher median ratings.\n",
        "\n",
        "Post-2010 movies showed a slight decline, possibly due to changing audience preferences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFu4xreNphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey_0qi68phqO"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "Helps platforms promote classic high-rated movies to boost engagement.\n",
        "\n",
        "Studios can analyze modern audience behavior and adjust production quality.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "If businesses over-prioritize classics, newer films may struggle to gain visibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ55k-q6phqO"
      },
      "source": [
        "#### Top 10 Countries Producing Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 9 visualization code\n",
        "country_list = [country for sublist in titles_df['production_countries'] for country in sublist]\n",
        "country_counts = Counter(country_list).most_common(10)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=[x[1] for x in country_counts], y=[x[0] for x in country_counts], palette='Blues_r')\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Country\")\n",
        "plt.title(\"Top 10 Countries Producing Content\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCFgpxoyphqP"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVxDimi2phqP"
      },
      "source": [
        "A scatter plot helps analyze whether longer movies receive higher ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVtJsKN_phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngGi97qjphqQ"
      },
      "source": [
        "Movies between 90-120 minutes had the best average IMDb scores.\n",
        "\n",
        "Extremely short or long movies had mixed reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lssrdh5qphqQ"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBpY5ekJphqQ"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "Studios can optimize movie lengths for maximum audience satisfaction.\n",
        "\n",
        "Streaming platforms can adjust recommendations based on runtime preferences.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "Over-reliance on runtime data might discourage experimental films.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      },
      "source": [
        "#### Distribution of Number of Seasons in TV Shows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "outputs": [],
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(titles_df[titles_df['type'] == 'SHOW']['seasons'], bins=20, kde=True, color='red')\n",
        "plt.xlabel(\"Number of Seasons\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Number of Seasons in TV Shows\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M8mcRywphqQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8agQvks0phqQ"
      },
      "source": [
        "A box plot shows how ratings vary across different age certifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgIPom80phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp13pnNzphqQ"
      },
      "source": [
        "R-rated movies had higher median IMDb scores than PG or PG-13 movies.\n",
        "\n",
        "G-rated movies had lower variance, suggesting consistent but lower ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMzcOPDDphqR"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Ka1PC2phqR"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "Helps marketing teams target appropriate age groups.\n",
        "\n",
        "Streaming services can curate family-friendly vs. adult content better.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "Ignoring lower-rated content could mean missing out on key audience segments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-EpHcCOp1ci"
      },
      "source": [
        "#### Top 10 Most Popular Movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "outputs": [],
      "source": [
        "# Chart - 11 visualization code\n",
        "top_popular = titles_df.nlargest(10, 'tmdb_popularity')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(y=top_popular['title'], x=top_popular['tmdb_popularity'], palette='cividis')\n",
        "plt.xlabel(\"TMDB Popularity\")\n",
        "plt.ylabel(\"Movie Title\")\n",
        "plt.title(\"Top 10 Most Popular Movies\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_VqEhTip1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vsMzt_np1ck"
      },
      "source": [
        "A heatmap visualizes correlations between numerical variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGJKyg5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      },
      "source": [
        "IMDb score was strongly correlated with TMDB score.\n",
        "\n",
        "Votes had a moderate correlation with IMDb score, meaning engagement affects ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "druuKYZpp1ck"
      },
      "source": [
        "✅ Yes.\n",
        "\n",
        "Helps identify which features impact movie ratings the most.\n",
        "\n",
        "Can guide recommendation algorithm improvements.\n",
        "\n",
        "❌ Negative Impact?\n",
        "\n",
        "Relying only on highly correlated features might ignore other hidden factors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3dbpmDWp1ck"
      },
      "source": [
        "#### Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "outputs": [],
      "source": [
        "# Chart - 12 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(titles_df[['imdb_score', 'imdb_votes', 'tmdb_score', 'tmdb_popularity']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylSl6qgtp1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2xqNkiQp1ck"
      },
      "source": [
        "Helped identify relationships between IMDb score, votes, and popularity.\n",
        "\n",
        "Confirmed that high IMDb scores often correspond to high votes and popularity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWILFDl5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-lUsV2mp1ck"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7G43BXep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwDJXsLp1cl"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag9LCva-p1cl"
      },
      "source": [
        "#### IMDb Score Distribution for Top 10 Genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "outputs": [],
      "source": [
        "# Chart - 13 visualization code\n",
        "top_genres = [genre[0] for genre in genre_counts]\n",
        "titles_df['top_genre'] = titles_df['genres'].apply(lambda x: x[0] if x and x[0] in top_genres else None)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='top_genre', y='imdb_score', data=titles_df, palette='plasma')\n",
        "plt.xlabel(\"Genre\")\n",
        "plt.ylabel(\"IMDb Score\")\n",
        "plt.title(\"IMDb Score Distribution for Top 10 Genres\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6MkPsBcp1cl"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V22bRsFWp1cl"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cELzS2fp1cl"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      },
      "source": [
        "Helped identify relationships between IMDb score, votes, and popularity.\n",
        "Confirmed that high IMDb scores often correspond to high votes and popularity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MPXvC8up1cl"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL8l1tdLp1cl"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "#### Chart - 14 - Correlation Heatmap of Key Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "outputs": [],
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(12, 6))\n",
        "corr_columns = ['imdb_score', 'imdb_votes', 'tmdb_score', 'tmdb_popularity', 'runtime', 'seasons']\n",
        "sns.heatmap(titles_df[corr_columns].corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap of Key Features\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSqtnDqZNRR"
      },
      "source": [
        "Confirmed that redundant features should be dropped to avoid overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29F0dvdveiT"
      },
      "source": [
        "#### Chart - 15 - Pair Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "outputs": [],
      "source": [
        "# Pair Plot visualization code\n",
        "import seaborn as sns\n",
        "\n",
        "corr_columns = ['imdb_score', 'imdb_votes', 'tmdb_score', 'tmdb_popularity', 'runtime']\n",
        "sns.pairplot(titles_df[corr_columns], diag_kind='kde', corner=True)\n",
        "plt.suptitle(\"Pair Plot of Key Features\", y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXh0U9oCveiU"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMmPjTByveiU"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22aHeOlLveiV"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQ8RGwHveiV"
      },
      "source": [
        "Helped visualize relationships between selected features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7MS06SUHkB-"
      },
      "source": [
        "### **Three Hypothetical Statements for Hypothesis Testing**  \n",
        "\n",
        "Based on the dataset and visualizations, here are **three hypothetical statements** we can test:  \n",
        "\n",
        "1. **Movies have a higher average IMDb score than TV Shows.**  \n",
        "   - \\( H_0 \\) (Null Hypothesis): There is no significant difference in IMDb scores between Movies and TV Shows.  \n",
        "   - \\( H_a \\) (Alternative Hypothesis): Movies have significantly higher IMDb scores than TV Shows.  \n",
        "\n",
        "2. **The number of IMDb votes is positively correlated with IMDb scores.**  \n",
        "   - \\( H_0 \\) (Null Hypothesis): There is no correlation between IMDb votes and IMDb scores.  \n",
        "   - \\( H_a \\) (Alternative Hypothesis): IMDb votes and IMDb scores are positively correlated.  \n",
        "\n",
        "3. **Action movies are more popular (higher TMDB popularity) than Drama movies.**  \n",
        "   - \\( H_0 \\) (Null Hypothesis): There is no significant difference in TMDB popularity between Action and Drama movies.  \n",
        "   - \\( H_a \\) (Alternative Hypothesis): Action movies have higher TMDB popularity than Drama movies.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "### **Hypothesis 1: IMDb Scores of Movies vs. TV Shows**  \n",
        "- **Null Hypothesis (\\(H_0\\))**: There is no significant difference in the average IMDb scores between Movies and TV Shows.  \n",
        "- **Alternate Hypothesis (\\(H_a\\))**: Movies have significantly different IMDb scores compared to TV Shows.  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import scipy.stats as stats\n",
        "titles_df = titles_df.dropna(subset=['imdb_score'])\n",
        "movies_scores = titles_df[titles_df['type'] == 'MOVIE']['imdb_score']\n",
        "tv_scores = titles_df[titles_df['type'] == 'SHOW']['imdb_score']\n",
        "t_stat1, p_value1 = stats.ttest_ind(movies_scores, tv_scores, equal_var=False)\n",
        "print(\"Hypothesis 1: IMDb Scores of Movies vs. TV Shows\")\n",
        "print(f\"T-Statistic: {t_stat1:.4f}, P-Value: {p_value1:.4f}\")\n",
        "if p_value1 < 0.05:\n",
        "    print(\"Result: Reject the Null Hypothesis (IMDb scores are significantly different)\")\n",
        "else:\n",
        "    print(\"Result: Fail to Reject the Null Hypothesis (No significant difference in IMDb scores)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "Independent t-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "To Compare means of two independent groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "### **Hypothesis 2: Correlation Between IMDb Votes and IMDb Scores**  \n",
        "- **Null Hypothesis (\\(H_0\\))**: There is no significant correlation between the number of IMDb votes and IMDb scores.  \n",
        "- **Alternate Hypothesis (\\(H_a\\))**: IMDb votes and IMDb scores are positively correlated.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Hypothesis 2: Correlation between IMDb Votes and IMDb Scores\n",
        "correlation, p_value2 = stats.pearsonr(titles_df['imdb_votes'].fillna(0), titles_df['imdb_score'].fillna(0))\n",
        "print(\"\\nHypothesis 2: Correlation Between IMDb Votes and IMDb Scores\")\n",
        "print(f\"Correlation Coefficient: {correlation:.4f}, P-Value: {p_value2:.4f}\")\n",
        "if p_value2 < 0.05:\n",
        "    print(\"Result: Reject the Null Hypothesis (There is a significant correlation between IMDb votes and IMDb scores)\")\n",
        "else:\n",
        "    print(\"Result: Fail to Reject the Null Hypothesis (No significant correlation)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "Pearson correlation test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd15vwWVpUZf"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        "To check linear relationship between two numerical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH"
      },
      "source": [
        "### Hypothetical Statement - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "### **Hypothesis 3: TMDB Popularity of Action vs. Drama Movies**  \n",
        "- **Null Hypothesis (\\(H_0\\))**: There is no significant difference in TMDB popularity between Action and Drama movies.  \n",
        "- **Alternate Hypothesis (\\(H_a\\))**: Action movies are significantly more popular than Drama movies (higher TMDB popularity).  \n",
        "\n",
        "Now, let's proceed with statistical testing and conclusions! 🚀\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Hypothesis 3: TMDB Popularity of Action vs. Drama Movies\n",
        "action_movies = titles_df[titles_df['genres'].apply(lambda x: 'action' in x)]['tmdb_popularity']\n",
        "drama_movies = titles_df[titles_df['genres'].apply(lambda x: 'drama' in x)]['tmdb_popularity']\n",
        "t_stat3, p_value3 = stats.ttest_ind(action_movies, drama_movies, equal_var=False, nan_policy='omit')\n",
        "print(\"\\nHypothesis 3: Action vs. Drama Movies - TMDB Popularity\")\n",
        "print(f\"T-Statistic: {t_stat3:.4f}, P-Value: {p_value3:.4f}\")\n",
        "if p_value3 < 0.05:\n",
        "    print(\"Result: Reject the Null Hypothesis (Action movies are significantly more popular than Drama movies)\")\n",
        "else:\n",
        "    print(\"Result: Fail to Reject the Null Hypothesis (No significant difference in popularity)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLW572S8pZyI"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "One-Sample t-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWbDXHzopZyI"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "To check if the mean of a sample is significantly different from a given value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 1. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "missing_columns = ['imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score']\n",
        "for col in missing_columns:\n",
        "    if titles_df[col].dtype in ['float64', 'int64']:\n",
        "        titles_df[col].fillna(titles_df[col].mean(), inplace=True)\n",
        "    else:\n",
        "        titles_df[col].fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# Drop rows with missing values in critical columns\n",
        "titles_df.dropna(subset=['imdb_score'], inplace=True)\n",
        "\n",
        "# Convert genres from string lists to actual lists\n",
        "titles_df['genres'] = titles_df['genres'].apply(lambda x: eval(x) if isinstance(x, str) else [])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wuGOrhz0itI"
      },
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixusLtI0pqI"
      },
      "source": [
        "### **Missing Value Imputation Techniques Used and Their Justification**  \n",
        "\n",
        "1. **Mean Imputation for Numerical Columns (`imdb_score`, `imdb_votes`, `tmdb_popularity`, `tmdb_score`)**  \n",
        "   - **Why?** The mean is used to replace missing values in numerical columns because it preserves the overall distribution of data while preventing bias towards extreme values. This is effective when the missing values are **randomly distributed** and the data follows a **normal distribution**.  \n",
        "\n",
        "2. **Constant Imputation (`\"Unknown\"`) for Categorical or Non-Numeric Data**  \n",
        "   - **Why?** For non-numeric data (e.g., missing categorical values), replacing missing entries with `\"Unknown\"` ensures that the data remains usable for analysis without making misleading assumptions. This technique is useful when missing values do not follow a predictable pattern.  \n",
        "\n",
        "3. **Row Deletion for Critical Missing Values (`imdb_score`)**  \n",
        "   - **Why?** Since `imdb_score` is crucial for hypothesis testing, rows with missing values in this column were **dropped** to prevent bias in statistical analysis. This method ensures that the results remain reliable by avoiding artificially imputed values that could distort findings.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 2. Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "outlier_columns = ['imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score']\n",
        "for col in outlier_columns:\n",
        "    Q1 = titles_df[col].quantile(0.25)\n",
        "    Q3 = titles_df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    titles_df = titles_df[(titles_df[col] >= lower_bound) & (titles_df[col] <= upper_bound)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578E2V7j08f6"
      },
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGZz5OrT1HH-"
      },
      "source": [
        "### **Outlier Treatment Techniques Used and Justification**  \n",
        "\n",
        "1. **Interquartile Range (IQR) Method**  \n",
        "   - **What it does:** Identifies and removes values that fall outside the range **[Q1 - 1.5 * IQR, Q3 + 1.5 * IQR]**, where Q1 and Q3 are the 25th and 75th percentiles, respectively.  \n",
        "   - **Why used?** This method effectively handles extreme values while preserving the majority of the data distribution. It is particularly useful for **IMDb scores, IMDb votes, TMDB popularity, and TMDB scores**, which may have long-tailed distributions.  \n",
        "   - **Effect:** Helps in reducing the influence of extreme outliers, leading to **more reliable statistical analyses and hypothesis testing**.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 3. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "titles_df['type_encoded'] = label_encoder.fit_transform(titles_df['type'])\n",
        "titles_df['age_certification'] = titles_df['age_certification'].astype(str)\n",
        "titles_df['age_certification_encoded'] = label_encoder.fit_transform(titles_df['age_certification'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "### **Categorical Encoding Techniques Used and Justification**  \n",
        "\n",
        "1. **Label Encoding** (Used for `type` and `age_certification`)  \n",
        "   - **What it does:** Converts categorical values into numerical values (e.g., `\"MOVIE\"` → `0`, `\"SHOW\"` → `1`).  \n",
        "   - **Why used?** Label encoding is effective when the categorical variable has **only a few unique values** (such as `type` with only \"MOVIE\" and \"SHOW\") and there is **no ordinal relationship** between them.  \n",
        "\n",
        "2. **String Conversion for Encoding** (Used for `age_certification`)  \n",
        "   - **What it does:** Ensures that categorical values are treated as strings before applying Label Encoding.  \n",
        "   - **Why used?** Some values may have mixed data types, so converting them to strings avoids errors during encoding.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwf50b-R2tYG"
      },
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMQiZwjn3iu7"
      },
      "source": [
        "#### 1. Expand Contraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "outputs": [],
      "source": [
        "# Expand Contraction\n",
        "import re\n",
        "\n",
        "# Custom dictionary for common contractions\n",
        "contractions_dict = {\n",
        "    \"can't\": \"cannot\", \"won't\": \"will not\", \"n't\": \" not\",\n",
        "    \"it's\": \"it is\", \"i'm\": \"i am\", \"she's\": \"she is\", \"he's\": \"he is\",\n",
        "    \"they're\": \"they are\", \"we're\": \"we are\", \"you're\": \"you are\",\n",
        "    \"i've\": \"i have\", \"we've\": \"we have\", \"they've\": \"they have\",\n",
        "    \"isn't\": \"is not\", \"doesn't\": \"does not\", \"aren't\": \"are not\",\n",
        "    \"wasn't\": \"was not\", \"weren't\": \"were not\", \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\", \"shouldn't\": \"should not\", \"wouldn't\": \"would not\"\n",
        "}\n",
        "\n",
        "# Function to expand contractions manually\n",
        "def expand_contractions(text):\n",
        "    if isinstance(text, str):\n",
        "        for contraction, expanded in contractions_dict.items():\n",
        "            text = re.sub(r'\\b' + re.escape(contraction) + r'\\b', expanded, text, flags=re.IGNORECASE)\n",
        "    return text\n",
        "\n",
        "# Apply to the 'description' column\n",
        "titles_df['description'] = titles_df['description'].apply(expand_contractions)\n",
        "\n",
        "# Display sample result\n",
        "print(titles_df[['title', 'description']].head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVIkgGqN3qsr"
      },
      "source": [
        "#### 2. Lower Casing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "outputs": [],
      "source": [
        "# Lower Casing\n",
        "# Convert text to lowercase\n",
        "titles_df['description'] = titles_df['description'].astype(str).str.lower()\n",
        "\n",
        "# Display sample result\n",
        "print(titles_df[['title', 'description']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkPnILGE3zoT"
      },
      "source": [
        "#### 3. Removing Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "outputs": [],
      "source": [
        "# Remove Punctuations\n",
        "import string\n",
        "\n",
        "# Function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation)) if isinstance(text, str) else text\n",
        "\n",
        "# Apply function to the 'description' column\n",
        "titles_df['description'] = titles_df['description'].apply(remove_punctuation)\n",
        "\n",
        "# Display sample result\n",
        "print(titles_df[['title', 'description']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlsf0x5436Go"
      },
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "outputs": [],
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "import re\n",
        "\n",
        "# Function to remove URLs from text\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'https?://\\S+|www\\.\\S+', '', text) if isinstance(text, str) else text\n",
        "\n",
        "# Apply function to 'description' column\n",
        "titles_df['description'] = titles_df['description'].apply(remove_urls)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove words containing digits\n",
        "def remove_words_with_digits(text):\n",
        "    return re.sub(r'\\b\\w*\\d\\w*\\b', '', text) if isinstance(text, str) else text\n",
        "\n",
        "# Apply function to 'description' column\n",
        "titles_df['description'] = titles_df['description'].apply(remove_words_with_digits)\n",
        "\n",
        "# Display sample result\n",
        "print(titles_df[['title', 'description']].head())\n"
      ],
      "metadata": {
        "id": "WT975W5qumb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT9DMSJo4nBL"
      },
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "outputs": [],
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load stopwords set\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words]) if isinstance(text, str) else text\n",
        "\n",
        "# Apply function to 'description' column\n",
        "titles_df['description'] = titles_df['description'].apply(remove_stopwords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "outputs": [],
      "source": [
        "# Remove White spaces\n",
        "# Function to remove extra whitespaces\n",
        "def remove_extra_whitespace(text):\n",
        "    return ' '.join(text.split()) if isinstance(text, str) else text\n",
        "\n",
        "# Apply function to 'description' column\n",
        "titles_df['description'] = titles_df['description'].apply(remove_extra_whitespace)\n",
        "\n",
        "# Display sample result\n",
        "print(titles_df[['title', 'description']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c49ITxTc407N"
      },
      "source": [
        "#### 6. Rephrase Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "outputs": [],
      "source": [
        "# Rephrase Text\n",
        "!pip install textblob\n",
        "from textblob import TextBlob\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to rephrase text using TextBlob\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download wordnet if not available\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Function to replace words with synonyms\n",
        "def rephrase_text_fast(text):\n",
        "    words = text.split()\n",
        "    rephrased_words = []\n",
        "    for word in words:\n",
        "        synonyms = wordnet.synsets(word)\n",
        "        if synonyms:\n",
        "            rephrased_words.append(synonyms[0].lemmas()[0].name())  # Choose the first synonym\n",
        "        else:\n",
        "            rephrased_words.append(word)\n",
        "    return ' '.join(rephrased_words)\n",
        "\n",
        "# Apply function to 'description' column\n",
        "titles_df['description'] = titles_df['description'].apply(rephrase_text_fast)\n",
        "\n",
        "# Display sample result\n",
        "print(titles_df[['title', 'description']].head())\n",
        "\n"
      ],
      "metadata": {
        "id": "8QiR-gOku_5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeJFEK0N496M"
      },
      "source": [
        "#### 7. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "import re\n",
        "\n",
        "# Function to tokenize words without nltk\n",
        "def tokenize_words_regex(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower()) if isinstance(text, str) else text\n",
        "\n",
        "# Apply function to 'description' column\n",
        "titles_df['word_tokens'] = titles_df['description'].apply(tokenize_words_regex)\n",
        "\n",
        "# Display sample result\n",
        "print(titles_df[['title', 'word_tokens']].head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ExmJH0g5HBk"
      },
      "source": [
        "#### 8. Text Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "outputs": [],
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download resources if needed\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Function to apply stemming\n",
        "def stem_text(text):\n",
        "    return ' '.join([stemmer.stem(word) for word in text.split()]) if isinstance(text, str) else text\n",
        "\n",
        "# Apply function to 'description' column\n",
        "titles_df['stemmed_description'] = titles_df['description'].apply(stem_text)\n",
        "\n",
        "# Display sample result\n",
        "print(titles_df[['title', 'stemmed_description']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNqERVU536h"
      },
      "source": [
        "##### Which text normalization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9jKVxE06BC1"
      },
      "source": [
        "### **Text Normalization Techniques Used & Justification**  \n",
        "\n",
        "1. **Stemming (PorterStemmer)**  \n",
        "   - **What it does:** Reduces words to their root form by **removing suffixes** (e.g., `\"running\"` → `\"run\"`, `\"caring\"` → `\"care\"`).  \n",
        "   - **Why used?** Stemming is **fast and computationally efficient**, making it ideal for **large datasets** where slight inaccuracies in word reduction don’t affect results significantly.  \n",
        "\n",
        "2. **Lemmatization (WordNetLemmatizer)**  \n",
        "   - **What it does:** Converts words into their **base dictionary form** (e.g., `\"better\"` → `\"good\"`, `\"running\"` → `\"run\"`).  \n",
        "   - **Why used?** Lemmatization provides **more meaningful words** than stemming, making it useful for **text classification, sentiment analysis, and NLP applications requiring correct word forms**.  \n",
        "\n",
        "📌 **Which One is Better?**  \n",
        "- **Stemming** is **faster but less precise** (use for large-scale processing).  \n",
        "- **Lemmatization** is **more accurate but slower** (use when word meaning matters).  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5UmGsbsOxih"
      },
      "source": [
        "#### 9. Part of speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform POS tagging\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PqRRJAJvzatU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      },
      "source": [
        "#### 10. Text Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "outputs": [],
      "source": [
        "# Vectorizing Text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Text Vectorization using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "tfidf_matrix = vectorizer.fit_transform(titles_df['description'].astype(str))\n",
        "\n",
        "# Convert TF-IDF matrix to DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display sample result\n",
        "print(tfidf_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBMux9mC6MCf"
      },
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su2EnbCh6UKQ"
      },
      "source": [
        "### **Text Vectorization Technique Used & Justification**  \n",
        "\n",
        "🔹 **Technique Used:** **TF-IDF (Term Frequency-Inverse Document Frequency)**  \n",
        "\n",
        "🔹 **Why TF-IDF?**  \n",
        "- **Captures important words**: Unlike simple word counts, TF-IDF assigns **higher importance** to unique words while **reducing the weight** of common words (e.g., \"the\", \"is\").  \n",
        "- **Improves NLP performance**: Useful for tasks like **text similarity, search relevance, and recommendation systems**.  \n",
        "- **Handles high-dimensional data efficiently**: By limiting features using `max_features=5000`, it reduces computation time while keeping meaningful words.  \n",
        "\n",
        "📌 **Alternative Vectorization Methods:**  \n",
        "✔ **CountVectorizer** (Simple word frequency, less effective for distinguishing importance)  \n",
        "✔ **Word Embeddings (Word2Vec, BERT, etc.)** (More context-aware but computationally expensive)  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74aWNz2AliB"
      },
      "source": [
        "#### 1. Feature Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "outputs": [],
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Adaptive variance threshold based on dataset variance\n",
        "threshold = max(0.001, np.percentile(tfidf_df.var(), 10))  # Take 10th percentile variance as threshold\n",
        "selector = VarianceThreshold(threshold=threshold)\n",
        "tfidf_df_selected = pd.DataFrame(selector.fit_transform(tfidf_df), columns=tfidf_df.columns[selector.get_support()])\n",
        "# Use IMDb scores as a proxy target for feature selection\n",
        "y_proxy = titles_df['imdb_score'].apply(lambda x: 1 if x > titles_df['imdb_score'].median() else 0)\n",
        "\n",
        "# Train RandomForest for feature selection\n",
        "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "model.fit(tfidf_df, y_proxy)\n",
        "\n",
        "# Select top features based on importance\n",
        "important_features = np.argsort(model.feature_importances_)[-500:]\n",
        "tfidf_df_rf_selected = tfidf_df.iloc[:, important_features]\n",
        "# Apply Standard Scaling before feature selection\n",
        "scaler = StandardScaler()\n",
        "tfidf_df_scaled = pd.DataFrame(scaler.fit_transform(tfidf_df), columns=tfidf_df.columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DejudWSA-a0"
      },
      "source": [
        "#### 2. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "outputs": [],
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Use IMDb scores as a classification target (binary: high vs low)\n",
        "y_target = titles_df['imdb_score'].apply(lambda x: 1 if x > titles_df['imdb_score'].median() else 0)\n",
        "\n",
        "# Select top 300 features using ANOVA F-test\n",
        "selector = SelectKBest(score_func=f_classif, k=300)\n",
        "selected_features = selector.fit_transform(tfidf_df, y_target)\n",
        "\n",
        "# Get selected feature names\n",
        "selected_feature_names = tfidf_df.columns[selector.get_support()]\n",
        "tfidf_df_selected = pd.DataFrame(selected_features, columns=selected_feature_names)\n",
        "\n",
        "# Display selected feature set\n",
        "print(tfidf_df_selected.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMng2IbBLp7"
      },
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      },
      "source": [
        "### **Feature Selection Methods Used & Justification**  \n",
        "\n",
        "1️⃣ **Variance Threshold**  \n",
        "   - **What it does:** Removes features with low variance (i.e., features that do not change much across samples).  \n",
        "   - **Why used?** Eliminates **redundant or uninformative features**, improving model efficiency.  \n",
        "   - **Modification:** Used an **adaptive threshold** instead of a fixed one to avoid removing too many features.  \n",
        "\n",
        "2️⃣ **Random Forest Feature Importance**  \n",
        "   - **What it does:** Selects features based on importance scores from a **Random Forest classifier**.  \n",
        "   - **Why used?** Helps in **identifying the most impactful words** in the TF-IDF vectorized data.  \n",
        "   - **Modification:** Used **IMDb scores as a meaningful proxy target** instead of a random dummy target.  \n",
        "\n",
        "3️⃣ **SelectKBest with ANOVA F-test**  \n",
        "   - **What it does:** Selects the **top K features** that have the highest correlation with the target variable.  \n",
        "   - **Why used?** Helps pick the **most relevant features while avoiding overfitting**.  \n",
        "   - **Modification:** Used IMDb scores as a **binary classification target** (above/below median) for meaningful selection.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      },
      "source": [
        "##### Which all features you found important and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgaEstsBnaf"
      },
      "source": [
        "### **1️⃣ Text-Based Features (TF-IDF Selected Words)**\n",
        "📌 **Top Words Selected from TF-IDF**  \n",
        "- Words highly correlated with IMDb scores and movie popularity, such as:  \n",
        "  - `\"thriller\", \"drama\", \"suspense\", \"action\", \"comedy\", \"romance\"` → Genre-related terms influencing viewer interest.  \n",
        "  - `\"award\", \"winner\", \"critically\", \"nominated\"` → Words related to critically acclaimed content.  \n",
        "  - `\"sequel\", \"series\", \"franchise\"` → Indicates popular movie franchises with high engagement.  \n",
        "\n",
        "✔ **Why Important?**  \n",
        "- These words **differentiate high-rated movies** from low-rated ones.  \n",
        "- Helps in **recommendation systems** by understanding common themes in successful movies.  \n",
        "\n",
        "---\n",
        "\n",
        "### **2️⃣ Numerical Features (Scaled & Selected Features)**  \n",
        "📌 **Key Features from IMDb & TMDB Scores**  \n",
        "- **IMDb Score** → Directly impacts a movie’s success.  \n",
        "- **TMDB Popularity** → Determines how much engagement a movie gets.  \n",
        "- **IMDb Votes (Log-Transformed)** → Ensures high-vote movies are weighted correctly without outliers.  \n",
        "- **Average Score (IMDb + TMDB)** → A new feature created to balance both platforms.  \n",
        "\n",
        "✔ **Why Important?**  \n",
        "- These features **quantify audience reception** and **popularity trends**.  \n",
        "- Helps predict **what makes a movie successful**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **3️⃣ Categorical & Metadata Features**  \n",
        "📌 **Key Features from Categorical Encoding**  \n",
        "- **Type (Movie vs. TV Show)** → Affects engagement levels.  \n",
        "- **Age Certification** → Determines target audience preference.  \n",
        "- **Genres (Encoded)** → Helps cluster similar content.  \n",
        "\n",
        "✔ **Why Important?**  \n",
        "- These features **define content type and audience suitability**, which are **critical for recommendations and predictive analysis**.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqoHp30x9hH9"
      },
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "outputs": [],
      "source": [
        "# Transform Your data\n",
        "# Power Transformation for Normalization\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "pt = PowerTransformer()\n",
        "numeric_features = ['imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score']\n",
        "titles_df[numeric_features] = pt.fit_transform(titles_df[numeric_features])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 6. Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "outputs": [],
      "source": [
        "# Scaling your data\n",
        "# Scaling your data using StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numeric_features = ['imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score']\n",
        "titles_df[numeric_features] = scaler.fit_transform(titles_df[numeric_features])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UUpS68QDMuG"
      },
      "source": [
        "### 7. Dimesionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexQrXU-DjzY"
      },
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      },
      "source": [
        "### **Is Dimensionality Reduction Needed?**  \n",
        "\n",
        "Yes, **dimensionality reduction** can be beneficial, especially because **TF-IDF vectorization** creates **high-dimensional sparse data** (e.g., 5000+ word features). However, its necessity depends on the following factors:  \n",
        "\n",
        "---\n",
        "\n",
        "### **📌 When is Dimensionality Reduction Needed?**  \n",
        "✅ **High Number of Features:** Too many features (TF-IDF + numeric data) can lead to the **curse of dimensionality**, making the model slower and prone to overfitting.  \n",
        "✅ **Multicollinearity:** Many text-based features may be correlated, leading to redundant information.  \n",
        "✅ **Computational Efficiency:** Reducing dimensions speeds up model training and improves memory usage.  \n",
        "\n",
        "---\n",
        "\n",
        "### **📌 When is Dimensionality Reduction NOT Needed?**  \n",
        "❌ **If feature selection is already applied** (e.g., VarianceThreshold, RandomForest Importance, SelectKBest).  \n",
        "❌ **If interpretability is a priority** (e.g., PCA transforms features into components, making them less interpretable).  \n",
        "❌ **If only a few key features are used** (e.g., categorical & numeric metadata).  \n",
        "\n",
        "---\n",
        "\n",
        "### **Recommended Dimensionality Reduction Methods**  \n",
        "✔ **PCA (Principal Component Analysis)** → Best for compressing **high-dimensional TF-IDF** data while preserving variance.  \n",
        "✔ **Truncated SVD (LSA - Latent Semantic Analysis)** → More suited for **sparse text data** like TF-IDF.  \n",
        "✔ **Autoencoders (Deep Learning)** → If advanced deep learning models are used.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "outputs": [],
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "# Dimensionality Reduction using Truncated SVD (for TF-IDF)\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Reduce TF-IDF dimensions to 300 components\n",
        "svd = TruncatedSVD(n_components=300, random_state=42)\n",
        "tfidf_reduced = svd.fit_transform(tfidf_df)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "tfidf_df_reduced = pd.DataFrame(tfidf_reduced, columns=[f'component_{i+1}' for i in range(300)])\n",
        "\n",
        "# Display transformed data\n",
        "print(tfidf_df_reduced.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5CmagL3EC8N"
      },
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKr75IDuEM7t"
      },
      "source": [
        "### **Dimensionality Reduction Technique Used & Justification**  \n",
        "\n",
        "✔ **Technique Used:** **Truncated SVD (Latent Semantic Analysis - LSA)**  \n",
        "\n",
        "---\n",
        "\n",
        "### **📌 Why Truncated SVD?**  \n",
        "🔹 **Works well with sparse data (TF-IDF matrices)** → Unlike PCA, Truncated SVD can handle sparse, high-dimensional text data without converting it into a dense matrix.  \n",
        "🔹 **Reduces dimensionality while preserving meaning** → Instead of removing words, it **projects them into a lower-dimensional space** that captures semantic relationships.  \n",
        "🔹 **Speeds up model training** → Reducing TF-IDF dimensions to **300 components** ensures faster computations without losing too much information.  \n",
        "🔹 **Avoids overfitting** → Removes redundant information, making the model generalize better.  \n",
        "\n",
        "---\n",
        "\n",
        "### **📌 Alternative Methods Considered:**  \n",
        "✔ **PCA (Principal Component Analysis)** – Good for numerical data but **not ideal for sparse TF-IDF data**.  \n",
        "✔ **Autoencoders (Deep Learning)** – More powerful but **computationally expensive**.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 8. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = tfidf_df_reduced  # Use the reduced TF-IDF features\n",
        "y = titles_df['imdb_score']  # Predict IMDb score as the target\n",
        "\n",
        "# Split data into 80% train and 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=None)\n",
        "\n",
        "# Display shapes of split datasets\n",
        "print(f\"Training Data: {X_train.shape}, Testing Data: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      },
      "source": [
        "### **Data Splitting Ratio Used & Justification**  \n",
        "\n",
        "✔ **Train-Test Split Ratio:** **80% Train | 20% Test**  \n",
        "\n",
        "---\n",
        "\n",
        "### **📌 Why 80-20 Split?**  \n",
        "✅ **Balanced Learning & Evaluation:**  \n",
        "- **80% training data** ensures the model has **enough data** to learn patterns.  \n",
        "- **20% test data** allows proper **evaluation** without losing too much data for training.  \n",
        "\n",
        "✅ **Prevents Overfitting & Underfitting:**  \n",
        "- A **larger training set** (80%) helps the model **generalize well**.  \n",
        "- A **smaller test set** (20%) is enough to **assess performance** without excessive variance.  \n",
        "\n",
        "✅ **Standard Practice for Machine Learning Models:**  \n",
        "- Used in many real-world ML problems where **data size is moderate to large**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **📌 When to Use a Different Split?**  \n",
        "✔ **70-30 Split:** If you have a **small dataset**, a **larger test set (30%)** helps better evaluate performance.  \n",
        "✔ **90-10 Split:** If your dataset is **very large**, keeping **90% for training** can be beneficial.  \n",
        "✔ **Stratified Split:** If dealing with **classification tasks**, stratifying ensures class balance.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1XJ9OREExlT"
      },
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOzZv6IFROw"
      },
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKDIv7pFgcC"
      },
      "source": [
        "### **Is the Dataset Imbalanced?**  \n",
        "\n",
        "The dataset's balance depends on the **distribution of IMDb scores**. If most movies have similar ratings (e.g., clustered around 5-6), it indicates an **imbalance**, whereas a **uniform spread** across different score ranges suggests a **balanced dataset**.  \n",
        "\n",
        "To check for imbalance, we can analyze the **statistical summary** of IMDb scores (mean, median, quartiles) and visualize their distribution. If the data is **skewed**, with a majority of movies receiving similar ratings and very few in extreme categories, it means the dataset is imbalanced.  \n",
        "\n",
        "If we convert IMDb scores into **binary categories** (e.g., high-rated movies ≥7, low-rated <7) and one category significantly outweighs the other (e.g., 90% low-rated, 10% high-rated), the dataset is considered **imbalanced** for classification tasks.  \n",
        "\n",
        "In conclusion, if IMDb scores are **evenly distributed**, the dataset is **balanced**. However, if most values are concentrated in a specific range (e.g., mid-range scores), then the dataset is **imbalanced** and may require **resampling techniques** like oversampling or undersampling to improve model performance. 🚀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "outputs": [],
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Define features and target again\n",
        "X = tfidf_df_reduced\n",
        "y = titles_df['high_rating']\n",
        "\n",
        "# Check class distribution before balancing\n",
        "print(\"Class distribution before balancing:\", Counter(y))\n",
        "\n",
        "# Apply SMOTE only if there are two classes\n",
        "if len(np.unique(y)) > 1:\n",
        "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "    print(\"Class distribution after balancing:\", Counter(y_resampled))\n",
        "else:\n",
        "    print(\"Skipping SMOTE: Only one class present in the dataset.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIqpNgepFxVj"
      },
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbet1HwdGDTz"
      },
      "source": [
        "### **Technique Used to Handle Imbalanced Dataset & Justification**  \n",
        "\n",
        "✔ **Technique Used:** **SMOTE (Synthetic Minority Over-sampling Technique) & Threshold Adjustment**  \n",
        "\n",
        "---\n",
        "\n",
        "### **📌 Why SMOTE?**  \n",
        "SMOTE was used to **oversample the minority class** (high-rated movies) by **synthetically generating new data points** instead of duplicating existing ones.  \n",
        "\n",
        "✔ **Creates synthetic samples instead of duplicating existing ones**  \n",
        "✔ **Prevents model bias** toward the majority class (low-rated movies)  \n",
        "✔ **Improves model generalization** by ensuring the classifier learns from both high-rated and low-rated movies  \n",
        "\n",
        "---\n",
        "\n",
        "### **📌 Why Threshold Adjustment?**  \n",
        "Before applying SMOTE, the dataset was found to contain **only one class (`0`)**, meaning there were **no high-rated movies (`1`)** based on IMDb ≥ 7.  \n",
        "\n",
        "✔ **Lowering the IMDb threshold to 6.5** helped ensure that we had at least **some high-rated movies (`1`)** before applying SMOTE.  \n",
        "✔ **Avoids misclassification issues** by ensuring the dataset has a meaningful balance before oversampling.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Select features and target variable\n",
        "target = 'imdb_score'\n",
        "features = [col for col in titles_df.columns if col != target and titles_df[col].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(titles_df[features], titles_df[target], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForest model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R-squared Score: {r2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJBuiUVfxKd"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics = ['MSE', 'MAE', 'R2 Score']\n",
        "scores = [mse, mae, r2]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics, scores, color=['blue', 'green', 'red'])\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Scores\")\n",
        "plt.title(\"Model Evaluation Metrics\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qY1EAkEfxKe"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "UvvM4AxhH09B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.pruners import HyperbandPruner\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "# Define the objective function for Optuna with Hyperband\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 10, 30)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
        "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        bootstrap=bootstrap,\n",
        "        random_state=42\n",
        "    )\n",
        "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
        "    return -score\n",
        "\n",
        "# Run Bayesian Optimization with Optuna using Hyperband Pruner\n",
        "study = optuna.create_study(direction='minimize', pruner=HyperbandPruner())\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "best_model = RandomForestRegressor(**best_params, random_state=42)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_mse = -cv_scores.mean()\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Cross-Validation MSE: {cv_mse}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R-squared Score: {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negyGRa7fxKf"
      },
      "source": [
        "I have used Bayesian Optimization with a Hyperband pruner for hyperparameter optimization in the model.\n",
        "\n",
        "Why Hyperband?\n",
        "\n",
        "Speed & Efficiency\n",
        "\n",
        "Unlike traditional Bayesian optimization, Hyperband dynamically allocates resources to the best-performing trials while quickly eliminating underperforming ones. It avoids wasting time on bad hyperparameter configurations early. Best for Large Search Spaces\n",
        "\n",
        "Since we are tuning multiple hyperparameters (e.g., n_estimators, max_depth, min_samples_split, etc.), Hyperband efficiently narrows down the best combination without needing exhaustive searches.\n",
        "\n",
        "Built-in Early Stopping\n",
        "\n",
        "Instead of evaluating all trials equally, it stops poor configurations early and focuses computational power on the best ones.\n",
        "\n",
        "Works Well with Optuna\n",
        "\n",
        "Optuna’s HyperbandPruner() is integrated seamlessly with your RandomForestRegressor, making it an ideal choice for optimizing its hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfvqoZmBfxKf"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaLui8CcfxKf"
      },
      "source": [
        "There is a slight degradation meaning the Hyperband Optimization dealt with the overfitting."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = ['Cross-Validation MSE', 'Test MSE', 'MAE', 'R2 Score']\n",
        "scores = [cv_mse, mse, mae, r2]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics, scores, color=['blue', 'orange', 'green', 'red'])\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Scores\")\n",
        "plt.title(\"Model Evaluation Metrics with Hyperband Optimization\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7VWKA8jUIxfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Handle missing values by imputing with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "# Train the Gradient Boosting Regressor model\n",
        "model = GradientBoostingRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R-squared Score: {r2}\")\n"
      ],
      "metadata": {
        "id": "eep-or92I-2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYfwnehpsJ1"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics = ['Test MSE', 'MAE', 'R2 Score']\n",
        "scores = [mse, mae, r2]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics, scores, color=['blue', 'orange', 'green'])\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Scores\")\n",
        "plt.title(\"Gradient Boosting Regression Model Evaluation Metrics\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingRandomSearchCV\n",
        "# Define parameter grid for successive halving tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150, 200, 300],\n",
        "    'max_depth': [3, 6, 9, 12],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize Gradient Boosting Regressor model\n",
        "gbr_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Perform hyperparameter tuning using Halving Random Search\n",
        "halving_search = HalvingRandomSearchCV(\n",
        "    gbr_model, param_grid, factor=3, random_state=42, n_jobs=-1, verbose=1\n",
        ")\n",
        "halving_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_gbr_model = halving_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred_gbr = best_gbr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse_gbr = mean_squared_error(y_test, y_pred_gbr)\n",
        "mae_gbr = mean_absolute_error(y_test, y_pred_gbr)\n",
        "r2_gbr = r2_score(y_test, y_pred_gbr)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Tuned Gradient Boosting Regressor with Successive Halving:\")\n",
        "print(f\"Mean Squared Error: {mse_gbr}\")\n",
        "print(f\"Mean Absolute Error: {mae_gbr}\")\n",
        "print(f\"R-squared Score: {r2_gbr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAih1iBOpsJ2"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      },
      "source": [
        "Successive Halving is an efficient hyperparameter tuning method that systematically eliminates the least promising configurations in multiple rounds of training. It works as follows:\n",
        "\n",
        "Start with a large pool of random hyperparameter configurations and allocate limited resources (e.g., training epochs, number of trees, or data samples).\n",
        "\n",
        "Evaluate models on a small subset of data with fewer computational resources.\n",
        "\n",
        "Eliminate the worst-performing half (or a fraction) of configurations after each iteration.\n",
        "\n",
        "Increase resource allocation for the remaining models and continue until a final, best-performing model remains.\n",
        "\n",
        "Why are we using Successive Halving?\n",
        "\n",
        "Faster than RandomizedSearchCV – It quickly narrows down promising hyperparameter sets by eliminating weaker ones early.\n",
        "\n",
        "More efficient than Grid Search – It does not test every possible combination, reducing computational cost.\n",
        "\n",
        "Balances exploration and exploitation – It starts broad (like Random Search) but refines towards better models quickly.\n",
        "\n",
        "Scales well with large datasets – Instead of training all models fully, it allocates resources dynamically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74yRdG6UpsJ3"
      },
      "source": [
        "The model performance has improved after applying Successive Halving:\n",
        "\n",
        "Before Successive Halving:\n",
        "\n",
        "Mean Squared Error: 0.32672428966791633\n",
        "\n",
        "Mean Absolute Error: 0.41330779652951705\n",
        "\n",
        "R-squared Score: 0.7853820748868363\n",
        "\n",
        "After Successive Halving:\n",
        "\n",
        "MSE: 0.0462 (↓ Lower is better)\n",
        "\n",
        "MAE: 0.1545 (↓ Lower is better)\n",
        "\n",
        "R² Score: 0.9720 (↑ Higher is better)\n",
        "\n",
        "What Does This Mean?\n",
        "\n",
        "Lower MSE & MAE: The predictions are closer to actual IMDb scores after tuning.\n",
        "\n",
        "Higher R² Score: The model explains more variance in the IMDb scores, improving accuracy.\n",
        "\n",
        "Successive Halving worked well: It helped find better hyperparameters without excessive computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      },
      "source": [
        "1.Mean Squared Error (MSE): Indicates how far predictions deviate from actual values. Lower values mean more reliable predictions. High MSE could lead to poor decision-making in rating-based recommendations.\n",
        "\n",
        "2.Mean Absolute Error (MAE): Shows the average magnitude of errors. Lower MAE means the model predicts closer to actual values, crucial for content ranking accuracy.\n",
        "\n",
        "3.R-squared Score (R²): Measures how well the model explains variance. A high R² indicates the model effectively captures patterns, supporting business decisions based on user ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Initialize the XGBoost Regressor model\n",
        "xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"XGBoost Regressor:\")\n",
        "print(f\"Mean Squared Error: {mse_xgb}\")\n",
        "print(f\"Mean Absolute Error: {mae_xgb}\")\n",
        "print(f\"R-squared Score: {r2_xgb}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AN1z2sKpx6M"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics = ['MSE', 'MAE', 'R2 Score']\n",
        "scores_xgb = [mse_xgb, mae_xgb, r2_xgb]\n",
        "\n",
        "x = range(len(metrics))\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(x, scores_xgb, width=0.4, label='XGBoost', color='green', align='center')\n",
        "plt.xticks(x, metrics)\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Scores\")\n",
        "plt.title(\"XGBoost Regression Model Evaluation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PIHJqyupx6M"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import optuna\n",
        "import numpy as np\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
        "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
        "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n",
        "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 10.0)\n",
        "    }\n",
        "    model = XGBRegressor(**params, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    return mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "best_xgb_model = XGBRegressor(**best_params, random_state=42)\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Tuned XGBoost Regressor with Optuna:\")\n",
        "print(f\"Mean Squared Error: {mse_xgb}\")\n",
        "print(f\"Mean Absolute Error: {mae_xgb}\")\n",
        "print(f\"R-squared Score: {r2_xgb}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-qAgymDpx6N"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQMffxkwpx6N"
      },
      "source": [
        "I've implemented Optuna Optimization for hyperparameter tuning and cross-validation on the XGBoost model because this is one of the fastest and most efficient methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hykwinpx6N"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzVzZC6opx6N"
      },
      "source": [
        "There was a slight improvement in the R2 Score, making the accuracy of this model virtually similar to the RandomForest Regressor. The MSE and MAE significantly went down after tuning and cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVz9hHDKFms"
      },
      "source": [
        "The evaluation metrics considered for positive business impact are:\n",
        "\n",
        "Mean Squared Error (MSE)\n",
        "\n",
        "Why it matters: MSE penalizes larger errors more heavily, which ensures that the model doesn't produce wildly incorrect predictions.\n",
        "\n",
        "Business impact: A low MSE ensures that predicted IMDb scores are accurate, leading to better recommendations, improved user trust, and higher engagement.\n",
        "\n",
        "Mean Absolute Error (MAE)\n",
        "\n",
        "Why it matters: MAE provides an easy-to-interpret metric for average prediction error. Unlike MSE, it treats all errors equally without squaring them.\n",
        "\n",
        "Business impact: Lower MAE means more consistent predictions, reducing dissatisfaction among users when browsing for content based on predicted ratings.\n",
        "\n",
        "R-squared Score (R²)\n",
        "\n",
        "Why it matters: It indicates how well the model explains variance in IMDb scores. A high R² suggests that the model effectively captures patterns in user ratings.\n",
        "\n",
        "Business impact: A high R² ensures the model generalizes well, making it valuable for dynamic rating predictions, content ranking, and personalized recommendations.\n",
        "\n",
        "Overall Business Impact Accurate predictions improve content recommendations, leading to higher engagement on the platform. Reduced prediction errors lower the chances of misleading users with inaccurate ratings. Reliable predictions help businesses optimize marketing strategies for high-rated content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      },
      "source": [
        "I chose XGBoost Regressor as my final prediction model because it performs with the best accuracy with lesser chance of overfitting as compared to the Random Forest Regressor, also it has very low MAE and MSE meaning the model is performing with very less error in predicting the IMDb scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGl1hHyA_VK"
      },
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVTiIxBL-C"
      },
      "source": [
        "XGBoost (Extreme Gradient Boosting) is an optimized gradient boosting algorithm designed for efficiency, scalability, and high performance. It builds an ensemble of decision trees to improve predictive accuracy. The key advantages of XGBoost include:\n",
        "\n",
        "Gradient Boosting: Uses boosting technique to iteratively improve weak learners.\n",
        "\n",
        "Regularization (L1 & L2): Prevents overfitting.\n",
        "\n",
        "Handling Missing Data: Automatically manages missing values. Parallelization & Speed Optimization: Optimized for performance with GPU support.\n",
        "\n",
        "How It Works\n",
        "\n",
        "Boosting Framework: It creates multiple weak models (decision trees), each learning from the previous model’s mistakes.\n",
        "\n",
        "Tree Pruning: Uses a depth-wise approach to avoid overfitting. Weighted Residual Learning: Assigns weights to incorrect predictions to improve future iterations.\n",
        "\n",
        "Objective Function: Minimizes the loss function (e.g., Mean Squared Error for regression).\n",
        "\n",
        "Feature Importance using SHAP\n",
        "\n",
        "SHAP (SHapley Additive Explanations) provides a breakdown of how each feature influences the model’s predictions.\n",
        "\n",
        "SHAP Summary Plot: Shows the impact of all features.\n",
        "\n",
        "SHAP Bar Plot: Highlights the most important features. Business Impact\n",
        "\n",
        "Higher R² Score: Indicates the model explains a large portion of variance in IMDb scores.\n",
        "\n",
        "Lower MSE & MAE: Suggests accurate predictions, reducing errors in decision-making.\n",
        "\n",
        "Feature Explainability: Helps businesses understand which factors (e.g., director, budget, genre) impact IMDb ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyNgTHvd2WFk"
      },
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5McJBi2d8v"
      },
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "outputs": [],
      "source": [
        "# Save the File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      },
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "outputs": [],
      "source": [
        "# Load the File and predict unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kee-DAl2viO"
      },
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "In conclusion, these are the business impacts I found:\n",
        "\n",
        "Business Impacts\n",
        "\n",
        "Film studios can leverage predictions to estimate audience reception before release.\n",
        "\n",
        "Producers can adjust budgets and cast sizes to maximize IMDb scores.\n",
        "\n",
        "Streaming platforms can prioritize acquiring high-rated movies based on feature importance analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "lQ7QKXXCp7Bj",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "Yfr_Vlr8HBkt",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO"
      ],
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}